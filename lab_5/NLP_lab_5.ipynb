{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttJrxrraVrwQ"
      },
      "source": [
        "### 2. Download three Polish models from the Huggingface repository. These should be regular language models, which were not fine-tuned. E.g. HerBERT and papuGaPT2 are good examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-vSChVclCDuL"
      },
      "outputs": [],
      "source": [
        "model_1_name = 'allegro/herbert-base-cased'\n",
        "model_2_name = 'Twitter/twhin-bert-base'\n",
        "model_3_name = 'sdadas/polish-bart-base'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sacremoses\n",
        "# !pip install SentencePiece"
      ],
      "metadata": {
        "id": "ZT08d8Ty2GOJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def masked_language_modeling(model_name, sentence):\n",
        "  fill_mask = pipeline(task=\"fill-mask\",  model = model_name)\n",
        "  preds = fill_mask(sentence, top_k=3)\n",
        "  for pred in preds:\n",
        "    print(pred[\"sequence\"])"
      ],
      "metadata": {
        "id": "InAIOjw0duTW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUXW4hxIcm6b"
      },
      "source": [
        "### 3. Devise a method to test if the langage model understands Polish cases. E.g. testing for nominal case could be expressed as \"Warszawa to największe [MASK]\", and the masked word should be in nominative case. Create sentences for each case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_aPfMNEEclmP"
      },
      "outputs": [],
      "source": [
        "nominal_sentence = \"Warszawa to największe <mask>\"\n",
        "genitive_sentence = \"Mojej ulubionej <mask> nie ma w bibliotece.\"\n",
        "dative_sentence = \"Kupiłem prezent mojej <mask>.\"\n",
        "accusative_sentence = \"Zobaczyłem ostatnio bardzo ciekawy <mask>.\"\n",
        "locative_sentence = \"Staliśmy przy <mask> znajdującej się w centrum miasta.\"\n",
        "\n",
        "sentences_1 = {'Nominal sentence': nominal_sentence, 'Genitive sentence': genitive_sentence, 'Dative snetence': dative_sentence, 'Accusative sentence': accusative_sentence,'Locative sentence': locative_sentence}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NQQnLvFV264"
      },
      "source": [
        "#### **allegro/herbert-base-cased**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nar3ib_oCiHs",
        "outputId": "10745264-ce92-45d5-bd68-d595f2e03aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nominal sentence\n",
            "Warszawa to największe miasto\n",
            "Warszawa to największe …\n",
            "Warszawa to największe miasta\n",
            "\n",
            "\n",
            "Genitive sentence\n",
            "Mojej ulubionej książki nie ma w bibliotece.\n",
            "Mojej ulubionej powieści nie ma w bibliotece.\n",
            "Mojej ulubionej pozycji nie ma w bibliotece.\n",
            "\n",
            "\n",
            "Dative snetence\n",
            "Kupiłem prezent mojej mamie.\n",
            "Kupiłem prezent mojej żonie.\n",
            "Kupiłem prezent mojej córce.\n",
            "\n",
            "\n",
            "Accusative sentence\n",
            "Zobaczyłem ostatnio bardzo ciekawy film.\n",
            "Zobaczyłem ostatnio bardzo ciekawy artykuł.\n",
            "Zobaczyłem ostatnio bardzo ciekawy projekt.\n",
            "\n",
            "\n",
            "Locative sentence\n",
            "Staliśmy przy restauracji znajdującej się w centrum miasta.\n",
            "Staliśmy przy plaży znajdującej się w centrum miasta.\n",
            "Staliśmy przy ulicy znajdującej się w centrum miasta.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_1.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_1_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE8EzUA1cuIO"
      },
      "source": [
        "#### **Twitter/twhin-bert-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh-ei4gcGyYm",
        "outputId": "882965e7-9bd8-4fbd-dc89-c99aee6345b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nominal sentence\n",
            "Warszawa to największe miasto\n",
            "Warszawa to największe święto\n",
            "Warszawa to największe szczęście\n",
            "\n",
            "\n",
            "Genitive sentence\n",
            "Mojej ulubionej książki nie ma w bibliotece.\n",
            "Mojej ulubionej szkoły nie ma w bibliotece.\n",
            "Mojej ulubionej osoby nie ma w bibliotece.\n",
            "\n",
            "\n",
            "Dative snetence\n",
            "Kupiłem prezent mojej mamy.\n",
            "Kupiłem prezent mojej rodziny.\n",
            "Kupiłem prezent mojej mama.\n",
            "\n",
            "\n",
            "Accusative sentence\n",
            "Zobaczyłem ostatnio bardzo ciekawy film.\n",
            "Zobaczyłem ostatnio bardzo ciekawy mecz.\n",
            "Zobaczyłem ostatnio bardzo ciekawy grafik.\n",
            "\n",
            "\n",
            "Locative sentence\n",
            "Staliśmy przy stole znajdującej się w centrum miasta.\n",
            "Staliśmy przy ulicy znajdującej się w centrum miasta.\n",
            "Staliśmy przystanku znajdującej się w centrum miasta.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_1.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_2_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g7MLV6Uc8v1"
      },
      "source": [
        "#### **sdadas/polish-bart-base**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634,
          "referenced_widgets": [
            "80d69989eaa74b8b926d499005d6c1f2",
            "d8c51dc2e29c4de5b328ad7039fc51f9",
            "b9db81d421a149f7b420500b6bbc2be6",
            "c193a1365aa244cd936d4a13ce04107b",
            "b5830cf2ba184cac9d651aa28ca291d7",
            "85240282f9a1488fb9fa9574c1ec1294",
            "3b2e78a89a5a4cada77da3f1682d958d",
            "cc25b5a1b0524f769b1d85868af1ba0d",
            "0f0a83c81a1a4c0897856155d8412319",
            "a56d1712c27249908bc6eafddc5a6a86",
            "0d170948fd0247b2a6bf28f6ae2622fd",
            "fee0c1d974c84a80807de91daf9d30a7",
            "cae7e992edd94d2c9aca574cd220b849",
            "166438146cf14e34b059037aab266d52",
            "d9b5a26deee5489f8d61bb029ce8287d",
            "f95008c433c44c0ca3e62dc8ff8e92bb",
            "c300b57d47104138a64961c63e4be2f0",
            "49e81ad2a811455cb5fadc538b0f4a01",
            "7404ccb25e684068b8c0d18cce342a71",
            "45a8ebc5a575458a867d7d33181f5cd1",
            "661adb649b794f40b7bf1cce1e3d6c61",
            "a075cda5b2b947af830b2a97a014be20",
            "405b141ad9a44be79c10b34e9216dbfc",
            "78aad50bb73542b0821c7997c102f42d",
            "f6c5dab554034c39a3029897e65186c6",
            "48d0428107154eef932cf73387f5e9c3",
            "68ce87a0098240419170aeca191dbdba",
            "8becafa0546f486c81337c3182e64f56",
            "cb95a508662c4b68894f73838da3faea",
            "de53902e3b9e442f92416878be4ebd75",
            "abbf8ce7df7142f884edcbd6c170a99a",
            "77f2e8aa075d49d0967b644e0d74da9f",
            "d0e8993fc9b34b9ab2a04372b1253050"
          ]
        },
        "id": "zI9lGNdALfeM",
        "outputId": "62a59c23-33e1-4e1c-8b87-6046b9d13c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nominal sentence\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80d69989eaa74b8b926d499005d6c1f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.32M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fee0c1d974c84a80807de91daf9d30a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "405b141ad9a44be79c10b34e9216dbfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warszawa to największe miasto\n",
            "Warszawa to największe miasta\n",
            "Warszawa to największe centrum\n",
            "\n",
            "\n",
            "Genitive sentence\n",
            "Mojej ulubionej książki nie ma w bibliotece.\n",
            "Mojej ulubionej lektury nie ma w bibliotece.\n",
            "Mojej ulubionej bajki nie ma w bibliotece.\n",
            "\n",
            "\n",
            "Dative snetence\n",
            "Kupiłem prezent mojej żonie.\n",
            "Kupiłem prezent mojej mamie.\n",
            "Kupiłem prezent mojej córce.\n",
            "\n",
            "\n",
            "Accusative sentence\n",
            "Zobaczyłem ostatnio bardzo ciekawy film.\n",
            "Zobaczyłem ostatnio bardzo ciekawy serial.\n",
            "Zobaczyłem ostatnio bardzo ciekawy artykuł.\n",
            "\n",
            "\n",
            "Locative sentence\n",
            "Staliśmy przy font znajdującej się w centrum miasta.\n",
            "Staliśmy przy restauracji znajdującej się w centrum miasta.\n",
            "Staliśmy przy stacji znajdującej się w centrum miasta.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_1.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_3_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAaq0bBCWSsC"
      },
      "source": [
        "### 4. Devise a method to test long-range relationships such as gender. E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JekZtkTuYYpn"
      },
      "outputs": [],
      "source": [
        "sentences_2 = {'Sentence 1': 'On <mask> w domu, podczas gdy ona ćwiczyła na siłowni.',\n",
        "               'Sentence 2': 'Ona <mask> mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.',\n",
        "               'Sentence 3': 'One razem <mask> film w kinie, kiedy ja oglądałem ten sam film w domu.'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdFPCKu1etZx"
      },
      "source": [
        "#### **allegro/herbert-base-cased**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sn3JLqseO5u",
        "outputId": "f75d61b5-ea7e-4028-a657-c7a60e02af77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "On mieszkał w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On przebywał w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On siedział w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Ona zajmowała mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona prowadziła mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona zajęła mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "One razem robiły film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem pokazały film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem oglądają film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_2.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_1_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2V5lJo7ewyY"
      },
      "source": [
        "#### **Twitter/twhin-bert-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4XuSfxbekkm",
        "outputId": "5da21dc7-ec75-4905-fd2c-2c153ada55b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "On był w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On jest w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On został w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Ona sprząta mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona chciała mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona kupił mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "One razem robią film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem pokazują film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem ogląda film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_2.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_2_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_RDu9wde1Rw"
      },
      "source": [
        "#### **sdadas/polish-bart-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFOW9w50e28x",
        "outputId": "63cd05dc-d9f1-4cb5-9acb-7b24f1df19e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "On ćwi w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On tren w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "On był w domu, podczas gdy ona ćwiczyła na siłowni.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Ona sprzą mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona sama mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "Ona wynajm mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "One razem ogląd film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem ogląda film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "One razem z film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_2.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_3_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDt3YKL1fqR8"
      },
      "source": [
        "5. Check if the model captures real-world knolwedge. For instance a sentence \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jU6uMJgQggNA"
      },
      "outputs": [],
      "source": [
        "sentences_3 = {'Sentence 1': '<mask> wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.',\n",
        "               'Sentence 2': 'Żelazo <mask> w obecności tlenu, zmieniając się w rdzę.',\n",
        "               'Sentence 3': 'Rośliny <mask> dwutlenek węgla podczas procesu fotosyntezy.'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xMDgNPhnx0"
      },
      "source": [
        "#### **allegro/herbert-base-cased**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zifXFKSfEtG",
        "outputId": "7784caf8-f45c-40e7-a8c9-7a2edbf9cef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Słońce wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Ziemia wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Żelazo powstaje w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazo znika w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazo ginie w obecności tlenu, zmieniając się w rdzę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "Rośliny produkują dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny pobierają dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny zatrzymują dwutlenek węgla podczas procesu fotosyntezy.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_3.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_1_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQCmBU6ohm2t"
      },
      "source": [
        "#### **Twitter/twhin-bert-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw-NkQM7hlBc",
        "outputId": "9879ee51-f7e5-4d7e-8ecb-f28872ac74aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "Ukraina wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Putin wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Polska wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Żelazowa w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazonie w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazony w obecności tlenu, zmieniając się w rdzę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "Rośliny zapach dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny kolor dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny biały dwutlenek węgla podczas procesu fotosyntezy.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_3.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_2_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bux5CBQ9hme2"
      },
      "source": [
        "#### **sdadas/polish-bart-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK4vVIaXhlv5",
        "outputId": "3e786326-d6ff-43d1-a01c-9d7f6e9c9e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n",
            "W wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "Na wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
            "\n",
            "\n",
            "Sentence 2\n",
            "Żelazo może w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazo rozpada w obecności tlenu, zmieniając się w rdzę.\n",
            "Żelazo ulega w obecności tlenu, zmieniając się w rdzę.\n",
            "\n",
            "\n",
            "Sentence 3\n",
            "Rośliny te dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny wykorzystują dwutlenek węgla podczas procesu fotosyntezy.\n",
            "Rośliny wytwarza dwutlenek węgla podczas procesu fotosyntezy.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, sentence in sentences_3.items():\n",
        "  print(name)\n",
        "  masked_language_modeling(model_3_name, sentence)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68UBRievfyOF"
      },
      "source": [
        "6. Check zero-shot learning capabilites of the models. Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie [MASK]\" Try different prompts, to see if they make any difference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N7Vpxu9_dbSQ"
      },
      "outputs": [],
      "source": [
        "s1 = 'Ten film to był kiler. Nie mogłem się oderwać od ekranu. <mask>'\n",
        "s2 = 'Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. <mask>'\n",
        "s3 = 'Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. <mask>'\n",
        "s4 = 'Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. <mask>'\n",
        "s5 = 'Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. <mask>'\n",
        "\n",
        "sentences_5 = [s1, s2, s3, s4, s5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **allegro/herbert-base-cased**"
      ],
      "metadata": {
        "id": "8zyXBj3Xh-J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def generate_sentences(sentence, prompts, model_name):\n",
        "  model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "  sentences = []\n",
        "\n",
        "  for sentiment in prompts:\n",
        "      masked_sentence = sentence.replace(\"<mask>\", sentiment)\n",
        "      generated_text = generator(masked_sentence, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
        "      sentences.append(generated_text.strip())\n",
        "\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "K6dnDur9ssqQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7FnHXsSYvF9R"
      },
      "outputs": [],
      "source": [
        "prompts = [\"Wypowiedź ta miała zdecydowanie charakter \", \"Wypowiedź ta cechuje się wyraźnie pozytywnym \", \"To zdanie wydaje się być wyjątkowo \"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-2ZLiKPwE61",
        "outputId": "4581ba83-6495-479a-998f-83fdeb3b8ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta miała zdecydowanie charakter  polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny, polityczny polityczny, polityczny, polityczny, polityczny\n",
            "2: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta cechuje się wyraźnie pozytywnym  akcentem............................\n",
            "3: Ten film to był kiler. Nie mogłem się oderwać od ekranu. To zdanie wydaje się być wyjątkowo  ważne, ponieważ to jest film, który jest naprawdę dobry...................\n",
            "\n",
            "\n",
            "Sentence 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta miała zdecydowanie charakter  polityczny i polityczny, ale nie była nią też wypowiedź polityczna, przeciwnie, była nią wypowiedź polityczna, polityczna, polityczna, była to wypowiedź polityczna, polityczna,\n",
            "2: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta cechuje się wyraźnie pozytywnym  akcentem............................\n",
            "3: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. To zdanie wydaje się być wyjątkowo  ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i\n",
            "\n",
            "\n",
            "Sentence 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta miała zdecydowanie charakter  negatywny i negatywny, niestety, ale nie tylko, bo niestety, również i ja, byłem zaskoczony\n",
            "2: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta cechuje się wyraźnie pozytywnym  akcentem i jest bardzo dobra, ponieważ jest bardzo dobra dla mnie i rodziny, ponieważ jest bardzo\n",
            "3: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. To zdanie wydaje się być wyjątkowo  ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne i ważne\n",
            "\n",
            "\n",
            "Sentence 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta miała zdecydowanie charakter  osobisty, ponieważ była prowadzona przez osobę prywatną, prywatną, prywatną, prywatną, prywatną, prywatną, prywatną osobę, prywatną osobę, itd.\n",
            "2: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta cechuje się wyraźnie pozytywnym  wpływem na organizm i samopoczucie, ponieważ jest prowadzona przez osobę prowadzącą zajęcia, która jest osobą prywatną........\n",
            "3: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. To zdanie wydaje się być wyjątkowo  ważne, ponieważ jest ono ważne dla każdego, każdego z nas, każdego z nas, każdego z nas, każdego z nas, każdego z\n",
            "\n",
            "\n",
            "Sentence 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta miała zdecydowanie charakter  fotograficzny........................\n",
            "2: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta cechuje się wyraźnie pozytywnym  wpływem na otoczenie, ponieważ jest widoczna w kadrze...............\n",
            "3: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. To zdanie wydaje się być wyjątkowo  ważne, ponieważ jest ważne, ponieważ jest ważne, ponieważ jest ważne, ponieważ jest ważne, ponieważ jest ważne....\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "i=1\n",
        "for sentence in sentences_5:\n",
        "  print(f'Sentence {i}')\n",
        "  i+=1\n",
        "  sentences = generate_sentences(sentence, prompts, model_1_name)\n",
        "  print('1:', sentences[0])\n",
        "  print('2:', sentences[1])\n",
        "  print('3:', sentences[2])\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Twitter/twhin-bert-base**"
      ],
      "metadata": {
        "id": "CHM8lU2WlQ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "for sentence in sentences_5:\n",
        "  print(f'Sentence {i}')\n",
        "  i+=1\n",
        "  sentences = generate_sentences(sentence, prompts, model_2_name)\n",
        "  print('1:', sentences[0])\n",
        "  print('2:', sentences[1])\n",
        "  print('3:', sentences[2])\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt8sZ5fFwZQR",
        "outputId": "b757c0a9-58ef-43eb-c5b4-5f517dca8012"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta miała zdecydowanie charakter 77777777744444444444_4____\n",
            "2: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta cechuje się wyraźnie pozytywnym 7744444444444444444444\n",
            "3: Ten film to był kiler. Nie mogłem się oderwać od ekranu. To zdanie wydaje się być wyjątkowo 777777774444444444_4_____\n",
            "\n",
            "\n",
            "Sentence 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta miała zdecydowanie charakter 777777744444444444444444444\n",
            "2: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta cechuje się wyraźnie pozytywnym 77444444444444444444444\n",
            "3: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. To zdanie wydaje się być wyjątkowo 77444444444444444444444444\n",
            "\n",
            "\n",
            "Sentence 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta miała zdecydowanie charakter 77777777777\n",
            "2: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta cechuje się wyraźnie pozytywnym 7777777\n",
            "3: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. To zdanie wydaje się być wyjątkowo 7777777777\n",
            "\n",
            "\n",
            "Sentence 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta miała zdecydowanie charakter a777777777777777\n",
            "2: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta cechuje się wyraźnie pozytywnym a77777777777\n",
            "3: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. To zdanie wydaje się być wyjątkowo aa7777777777777\n",
            "\n",
            "\n",
            "Sentence 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BertForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta miała zdecydowanie charakter 7777777777777777777777\n",
            "2: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta cechuje się wyraźnie pozytywnym 777777777777777777\n",
            "3: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. To zdanie wydaje się być wyjątkowo 777777777777777777777\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **sdadas/polish-bart-base**"
      ],
      "metadata": {
        "id": "6ZjM4fDBlmjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "for sentence in sentences_5:\n",
        "  print(f'Sentence {i}')\n",
        "  i+=1\n",
        "  sentences = generate_sentences(sentence, prompts, model_3_name)\n",
        "  print('1:', sentences[0])\n",
        "  print('2:', sentences[1])\n",
        "  print('3:', sentences[2])\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlLYqeVRZOUa",
        "outputId": "7fcbfc60-55da-4255-eba2-21c298b7fbcc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BartForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta miała zdecydowanie charakter  _______________________________________________________________ film to była kilera. Nie miałem się oderwać z ekranu.Wypowiedź ta miał zdecydowanie charakter\n",
            "2: Ten film to był kiler. Nie mogłem się oderwać od ekranu. Wypowiedź ta cechuje się wyraźnie pozytywnym  _______________________________________________________________ film to jest kiler, film to cechuje się jednoznacznie pozytywnym .. Wypowiedź\n",
            "3: Ten film to był kiler. Nie mogłem się oderwać od ekranu. To zdanie wydaje się być wyjątkowo  _______________________________________________________________ To nie jest tak, że nie mogłem oderwać się od ekranu to był Kiler. film film\n",
            "\n",
            "\n",
            "Sentence 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BartForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta miała zdecydowanie charakter  Wypowiedzi ta miała niewątpliwie charakter wypowiedź ta miał zdecydowanie charakter. Wypowiedzi te miały zdecydowanie charakter.\n",
            "2: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. Wypowiedź ta cechuje się wyraźnie pozytywnym ______________________________________________________________ Zawsze poprawia mi się nastrój. Zawsze poprawia mnie nastrój. Zwykle poprawia mi humor. Dziś Była\n",
            "3: Spacer po parku zawsze poprawia mi nastrój. Dziś była piękna pogoda. To zdanie wydaje się być wyjątkowo _______________________________________________________________ Zawsze poprawia mi się nastrój. Dzisiaj była ładna pogoda. Dziś jest piękna pogoda, To zdanie\n",
            "\n",
            "\n",
            "Sentence 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BartForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta miała zdecydowanie charakter ___________________________________________________________ Wypowiadając się na ten temat miałem zdecydowanie charakter\n",
            "2: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. Wypowiedź ta cechuje się wyraźnie pozytywnym ___________________________________________________________ Wypowiedzi te charakteryzują się wyraźnie negatywnym ________________\n",
            "3: Nie mogłem znaleźć kluczy do mieszkania rano. Spóźniłem się na ważne spotkanie i to okropnie wpłynęło na cały mój dzień. To zdanie wydaje się być wyjątkowo ___________________________________________________________ To jest wyjątkowo  to jest wyjątkowo. To\n",
            "\n",
            "\n",
            "Sentence 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BartForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta miała zdecydowanie charakter powiedzi ta miała Zdecydowanie charakter ___________________________________________________________ Wypowiedź: Senio zaczął regularnie ćwi\n",
            "2: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. Wypowiedź ta cechuje się wyraźnie pozytywnym powiedź ten cechuje się Wyraźnie pozytywnym  ___________________________________________________________ Senio zaczął regularnie ćwi\n",
            "3: Ostatnio zacząłem regularnie ćwiczyć jogę. To pomaga mi utrzymać równowagę i poprawić kondycję fizyczną. To zdanie wydaje się być wyjątkowo ____________________________________________________________ Senio wydaje się jest wyjątkowo  Senio zaczyna być wyjątkowo.\n",
            "\n",
            "\n",
            "Sentence 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'BartForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta miała zdecydowanie charakter  zdecydowanie charakter ____________________________________________________________ Wypowiedzi ta miała Zdecydowanie charakter................____________________________________ Wy\n",
            "2: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. Wypowiedź ta cechuje się wyraźnie pozytywnym  się wyraźnie pozytywnym _______________________________________________________________ Wypowiedzi te cechuje się Wyraźnie pozytywnym\n",
            "3: Ostatnio zainteresowałem się fotografią krajobrazową. To fascynujące, jak natura potrafi być piękna. To zdanie wydaje się być wyjątkowo est piękna. To zdanie wydaje się być wyjątkowo   To zdanie Wydaje się być szczególnie\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NRS5JLdf7rG"
      },
      "source": [
        "8. Answer the following questions (2 points):\n",
        "\n",
        "i. Which of the models produced the best results?\n",
        "\n",
        "\n",
        "*   Zdecydowanie allegro/herbert-base-cased poradził sobie najlepiej w większości zadań\n",
        "\n",
        "\n",
        "\n",
        "ii. Was any of the models able to capture Polish grammar?\n",
        "\n",
        "*   allegro/herbert-base-cased\n",
        "\n",
        "iii. Was any of the models able to capture long-distant relationships between the words?\n",
        "\n",
        "*   Jedynie sdadas/polish-bart-base źle poradził sobie z tym zadaniem:\n",
        "\n",
        "Sentence 1\n",
        "\n",
        "On ćwi w domu, podczas gdy ona ćwiczyła na siłowni.\n",
        "\n",
        "On tren w domu, podczas gdy ona ćwiczyła na siłowni.\n",
        "\n",
        "On był w domu, podczas gdy ona ćwiczyła na siłowni.\n",
        "\n",
        "\n",
        "Sentence 2\n",
        "\n",
        "Ona sprzą mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
        "\n",
        "Ona sama mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
        "\n",
        "Ona wynajm mieszkanie, podczas gdy jej współlokatorzy sprzątali łazienkę.\n",
        "\n",
        "\n",
        "Sentence 3\n",
        "\n",
        "One razem ogląd film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
        "\n",
        "One razem ogląda film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
        "\n",
        "One razem z film w kinie, kiedy ja oglądałem ten sam film w domu.\n",
        "\n",
        "iv. Was any of the models able to capture world knowledge?\n",
        "\n",
        "\n",
        "*   Jedynie allegro/herbert-base-cased całkiem dobrze poradził sobie z tym zadaniem\n",
        "\n",
        "\n",
        "\n",
        "v. Was any of the models good at doing zero-shot classification?\n",
        "\n",
        "\n",
        "*   Modele generują kilka pierwszych słów, nie zawsze z sensem, później zaracają już tylko różne znaki.\n",
        "\n",
        "\n",
        "vi. What are the most striking errors made by the models?\n",
        "\n",
        "\n",
        "*   Generują zdania nie posidające sensu logicznego i gramatycznego.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBGks-Vg9riz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80d69989eaa74b8b926d499005d6c1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8c51dc2e29c4de5b328ad7039fc51f9",
              "IPY_MODEL_b9db81d421a149f7b420500b6bbc2be6",
              "IPY_MODEL_c193a1365aa244cd936d4a13ce04107b"
            ],
            "layout": "IPY_MODEL_b5830cf2ba184cac9d651aa28ca291d7"
          }
        },
        "d8c51dc2e29c4de5b328ad7039fc51f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85240282f9a1488fb9fa9574c1ec1294",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2e78a89a5a4cada77da3f1682d958d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b9db81d421a149f7b420500b6bbc2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc25b5a1b0524f769b1d85868af1ba0d",
            "max": 334,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f0a83c81a1a4c0897856155d8412319",
            "value": 334
          }
        },
        "c193a1365aa244cd936d4a13ce04107b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56d1712c27249908bc6eafddc5a6a86",
            "placeholder": "​",
            "style": "IPY_MODEL_0d170948fd0247b2a6bf28f6ae2622fd",
            "value": " 334/334 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "b5830cf2ba184cac9d651aa28ca291d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85240282f9a1488fb9fa9574c1ec1294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2e78a89a5a4cada77da3f1682d958d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc25b5a1b0524f769b1d85868af1ba0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0a83c81a1a4c0897856155d8412319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a56d1712c27249908bc6eafddc5a6a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d170948fd0247b2a6bf28f6ae2622fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fee0c1d974c84a80807de91daf9d30a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cae7e992edd94d2c9aca574cd220b849",
              "IPY_MODEL_166438146cf14e34b059037aab266d52",
              "IPY_MODEL_d9b5a26deee5489f8d61bb029ce8287d"
            ],
            "layout": "IPY_MODEL_f95008c433c44c0ca3e62dc8ff8e92bb"
          }
        },
        "cae7e992edd94d2c9aca574cd220b849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c300b57d47104138a64961c63e4be2f0",
            "placeholder": "​",
            "style": "IPY_MODEL_49e81ad2a811455cb5fadc538b0f4a01",
            "value": "tokenizer.json: 100%"
          }
        },
        "166438146cf14e34b059037aab266d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7404ccb25e684068b8c0d18cce342a71",
            "max": 3322139,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45a8ebc5a575458a867d7d33181f5cd1",
            "value": 3322139
          }
        },
        "d9b5a26deee5489f8d61bb029ce8287d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_661adb649b794f40b7bf1cce1e3d6c61",
            "placeholder": "​",
            "style": "IPY_MODEL_a075cda5b2b947af830b2a97a014be20",
            "value": " 3.32M/3.32M [00:00&lt;00:00, 31.2MB/s]"
          }
        },
        "f95008c433c44c0ca3e62dc8ff8e92bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c300b57d47104138a64961c63e4be2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e81ad2a811455cb5fadc538b0f4a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7404ccb25e684068b8c0d18cce342a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a8ebc5a575458a867d7d33181f5cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "661adb649b794f40b7bf1cce1e3d6c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a075cda5b2b947af830b2a97a014be20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "405b141ad9a44be79c10b34e9216dbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78aad50bb73542b0821c7997c102f42d",
              "IPY_MODEL_f6c5dab554034c39a3029897e65186c6",
              "IPY_MODEL_48d0428107154eef932cf73387f5e9c3"
            ],
            "layout": "IPY_MODEL_68ce87a0098240419170aeca191dbdba"
          }
        },
        "78aad50bb73542b0821c7997c102f42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8becafa0546f486c81337c3182e64f56",
            "placeholder": "​",
            "style": "IPY_MODEL_cb95a508662c4b68894f73838da3faea",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f6c5dab554034c39a3029897e65186c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de53902e3b9e442f92416878be4ebd75",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abbf8ce7df7142f884edcbd6c170a99a",
            "value": 239
          }
        },
        "48d0428107154eef932cf73387f5e9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f2e8aa075d49d0967b644e0d74da9f",
            "placeholder": "​",
            "style": "IPY_MODEL_d0e8993fc9b34b9ab2a04372b1253050",
            "value": " 239/239 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "68ce87a0098240419170aeca191dbdba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8becafa0546f486c81337c3182e64f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb95a508662c4b68894f73838da3faea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de53902e3b9e442f92416878be4ebd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbf8ce7df7142f884edcbd6c170a99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77f2e8aa075d49d0967b644e0d74da9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e8993fc9b34b9ab2a04372b1253050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}